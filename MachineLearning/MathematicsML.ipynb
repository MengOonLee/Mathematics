{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb4bff0-7a9b-477b-aed3-080c71788a28",
   "metadata": {},
   "source": [
    "# Mathematics for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea4fa6-d178-4c61-8266-a73a9d36d751",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a05a89-8fe5-458a-82a1-a27982f33088",
   "metadata": {},
   "source": [
    "### Gaussian distribution\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^\\frac{-(x - \\mu)^2}{2 \\sigma^2}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{p} = \n",
    "  \\begin{bmatrix}\n",
    "    \\mu \\\\\n",
    "    \\sigma\n",
    "  \\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de9f4d-8801-427a-a225-56cdc35d424c",
   "metadata": {},
   "source": [
    "### Inverse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c83e94dc-429e-42f7-ad77-1b505bf171e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.14285714  4.42857143  0.14285714]\n",
      " [ 2.64285714 -3.42857143 -0.14285714]\n",
      " [-1.14285714  1.42857143  0.14285714]]\n",
      "[ 3.  -0.5  0. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = [\n",
    "    [4, 6, 2],\n",
    "    [3, 4, 1],\n",
    "    [2, 8, 13]\n",
    "]\n",
    "Ainv = np.linalg.inv(A)\n",
    "print(Ainv)\n",
    "\n",
    "s = [9, 7, 2]\n",
    "\n",
    "r = np.linalg.solve(A, s)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9340dc-c343-4d24-a81d-30de36e0b7c9",
   "metadata": {},
   "source": [
    "### Eigenvalues & Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c0fe46-cfcf-4490-bf75-118eb04293a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues:\n",
      " [ 1. -4. -3.]\n",
      "Eigenvectors:\n",
      " [[-0.6882472  -0.66666667  0.40824829]\n",
      " [-0.6882472  -0.66666667 -0.40824829]\n",
      " [-0.22941573  0.33333333 -0.81649658]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "M = np.array([\n",
    "    [  4,   -5,  6],\n",
    "    [  7,   -8,  6],\n",
    "    [3/2, -1/2, -2]\n",
    "])\n",
    "vals, vecs = np.linalg.eig(M)\n",
    "# Eigenvalues\n",
    "print('Eigenvalues:\\n', vals)\n",
    "# Eigenvectors - Note, the eigenvectors are the columns of the output.\n",
    "print('Eigenvectors:\\n', vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfabf2f-fe54-41da-8a35-b772b6c60110",
   "metadata": {},
   "source": [
    "## Multivariate Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950cfce1-e333-44d7-ae65-5e833429c53e",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec55518-8d24-4acb-beea-c78af24a2938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999092042625951\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First we set the state of the network\n",
    "σ = np.tanh\n",
    "w1 = -5\n",
    "b1 = 5\n",
    "\n",
    "# Then we define the neuron activation.\n",
    "def a1(a0):\n",
    "    return σ(w1 * a0 + b1)\n",
    "  \n",
    "# Finally let's try the network out!\n",
    "# Replace x with 0 or 1 below,\n",
    "print(a1(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0926ac2-aab2-4479-9af6-1fe5e94dd6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76159416 -0.76159416]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First set up the network.\n",
    "sigma = np.tanh\n",
    "W = np.array([[-2, 4, -1], [6, 0, -3]])\n",
    "b = np.array([0.1, -2.5])\n",
    "\n",
    "# Define our input vector\n",
    "x = np.array([0.3, 0.4, 0.1])\n",
    "\n",
    "# Calculate the values by hand,\n",
    "# and replace a1_0 and a1_1 here (to 2 decimal places)\n",
    "# (Or if you feel adventurous, find the values with code!)\n",
    "z = W @ x + b\n",
    "a1 = np.array(sigma(z))\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb690d9-54c8-4ba8-a7de-8a547c1b9a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.09966799462495582\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First we set the state of the network\n",
    "σ = np.tanh\n",
    "w1 = 1.3\n",
    "b1 = -0.1\n",
    "\n",
    "# Then we define the neuron activation.\n",
    "def a1(a0):\n",
    "    z = w1 * a0 + b1\n",
    "    return σ(z)\n",
    "\n",
    "# Experiment with different values of x below.\n",
    "x = 0\n",
    "print(a1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec12211f-dd4a-4d66-9fd0-0609383c72cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1186026425530913\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First define our sigma function.\n",
    "sigma = np.tanh\n",
    "\n",
    "# Next define the feed-forward equation.\n",
    "def a1(w1, b1, a0):\n",
    "    z = w1 * a0 + b1\n",
    "    return sigma(z)\n",
    "\n",
    "# The individual cost function is the square of the difference between\n",
    "# the network output and the training data output.\n",
    "def C(w1, b1, x, y):\n",
    "    return (a1(w1, b1, x) - y)**2\n",
    "\n",
    "# This function returns the derivative of the cost function with\n",
    "# respect to the weight.\n",
    "def dCdw(w1, b1, x, y):\n",
    "    z = w1 * x + b1\n",
    "    dCda = 2 * (a1(w1, b1, x) - y) # Derivative of cost with activation\n",
    "    dadz = 1/np.cosh(z)**2 # derivative of activation with weighted sum z\n",
    "    dzdw = x # derivative of weighted sum z with weight\n",
    "    return dCda * dadz * dzdw # Return the chain rule product.\n",
    "\n",
    "# This function returns the derivative of the cost function with\n",
    "# respect to the bias.\n",
    "# It is very similar to the previous function.\n",
    "# You should complete this function.\n",
    "def dCdb(w1, b1, x, y):\n",
    "    z = w1 * x + b1\n",
    "    dCda = 2 * (a1(w1, b1, x) - y)\n",
    "    dadz = 1/np.cosh(z)**2\n",
    "    \"\"\" Change the next line to give the derivative of\n",
    "      the weighted sum, z, with respect to the bias, b. \"\"\"\n",
    "    dzdb = 1\n",
    "    return dCda * dadz * dzdb\n",
    "\n",
    "\"\"\"Test your code before submission:\"\"\"\n",
    "# Let's start with an unfit weight and bias.\n",
    "w1 = 2.3\n",
    "b1 = -1.2\n",
    "# We can test on a single data point pair of x and y.\n",
    "x = 0\n",
    "y = 1\n",
    "# Output how the cost would change\n",
    "# in proportion to a small change in the bias\n",
    "print(dCdb(w1, b1, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f22e4b-fcf2-483c-a9f3-f5ef21f2f33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7788340952508737\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the activation function.\n",
    "sigma = np.tanh\n",
    "\n",
    "# Let's use a random initial weight and bias.\n",
    "W = np.array([[-0.94529712, -0.2667356 , -0.91219181],\n",
    "    [2.05529992, 1.21797092, 0.22914497]])\n",
    "b = np.array([0.61273249, 1.6422662])\n",
    "\n",
    "# define our feed forward function\n",
    "def a1(a0):\n",
    "    # Notice the next line is almost the same as previously,\n",
    "    # except we are using matrix multiplication rather than scalar multiplication\n",
    "    # hence the '@' operator, and not the '*' operator.\n",
    "    z = W @ a0 + b\n",
    "    # Everything else is the same though,\n",
    "    return sigma(z)\n",
    "\n",
    "# Next, if a training example is,\n",
    "x = np.array([0.7, 0.6, 0.2])\n",
    "y = np.array([0.9, 0.6])\n",
    "\n",
    "# Then the cost function is,\n",
    "d = a1(x) - y # Vector difference between observed and expected activation\n",
    "C = d @ d # Absolute value squared of the difference.\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20618fa-64a9-4418-8ad8-4a59c476706d",
   "metadata": {},
   "source": [
    "### Newton-Raphson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eff812a-d914-4bf6-a68d-cb10a5cd5424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>f(x)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.990000</td>\n",
       "      <td>1.733108e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-36.474613</td>\n",
       "      <td>3.871975e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-30.422744</td>\n",
       "      <td>1.296022e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-25.384916</td>\n",
       "      <td>4.337012e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-21.193182</td>\n",
       "      <td>1.450848e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-17.707798</td>\n",
       "      <td>4.851113e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-14.812568</td>\n",
       "      <td>1.620886e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-12.410978</td>\n",
       "      <td>5.410173e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-10.423021</td>\n",
       "      <td>1.802993e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-8.782600</td>\n",
       "      <td>5.994279e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-7.435499</td>\n",
       "      <td>1.985174e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-6.337977</td>\n",
       "      <td>6.530275e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-5.456155</td>\n",
       "      <td>2.120398e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-4.766625</td>\n",
       "      <td>6.692936e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-4.258508</td>\n",
       "      <td>1.970466e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-3.933902</td>\n",
       "      <td>4.793270e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-3.788984</td>\n",
       "      <td>6.712292e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-3.761154</td>\n",
       "      <td>2.123257e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-3.760215</td>\n",
       "      <td>2.351946e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-3.760214</td>\n",
       "      <td>2.895888e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-3.760214</td>\n",
       "      <td>4.263256e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x          f(x)\n",
       "0    1.990000  1.733108e+01\n",
       "1  -36.474613  3.871975e+08\n",
       "2  -30.422744  1.296022e+08\n",
       "3  -25.384916  4.337012e+07\n",
       "4  -21.193182  1.450848e+07\n",
       "5  -17.707798  4.851113e+06\n",
       "6  -14.812568  1.620886e+06\n",
       "7  -12.410978  5.410173e+05\n",
       "8  -10.423021  1.802993e+05\n",
       "9   -8.782600  5.994279e+04\n",
       "10  -7.435499  1.985174e+04\n",
       "11  -6.337977  6.530275e+03\n",
       "12  -5.456155  2.120398e+03\n",
       "13  -4.766625  6.692936e+02\n",
       "14  -4.258508  1.970466e+02\n",
       "15  -3.933902  4.793270e+01\n",
       "16  -3.788984  6.712292e+00\n",
       "17  -3.761154  2.123257e-01\n",
       "18  -3.760215  2.351946e-04\n",
       "19  -3.760214  2.895888e-10\n",
       "20  -3.760214  4.263256e-14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def f(x):\n",
    "    return x**6/6 - 3*x**4 - 2*x**3/3 + 27*x**2/2 + 18*x - 30\n",
    "\n",
    "def d_f(x) :\n",
    "    # Complete this line with the derivative you have calculated.\n",
    "    return x**5 - 12*x**3 - 2*x**2 + 27*x  + 18\n",
    "\n",
    "x = 1.99\n",
    "\n",
    "d = {\"x\": [x], \"f(x)\": [f(x)]}\n",
    "for i in range(0, 20):\n",
    "    x = x - f(x) / d_f(x)\n",
    "    d[\"x\"].append(x)\n",
    "    d[\"f(x)\"].append(f(x))\n",
    "\n",
    "pd.DataFrame(d, columns=['x', 'f(x)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80300a88-8446-4da4-b7b6-45d94de95bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.063070629709697"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp\n",
    "\n",
    "def f(x):\n",
    "  return x**6/6 - 3*x**4 - 2*x**3/3 + 27*x**2/2 + 18*x - 30\n",
    "  \n",
    "x0 = 3.1\n",
    "sp.optimize.newton(f, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ea550-7d8b-4ea7-b066-3fdb554bc8f1",
   "metadata": {},
   "source": [
    "### Lagrange Multipliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3ec3b0-4198-4d0a-a86e-b4b8d5146524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 0.930942\n",
      "y = -1.21083\n",
      "λ = -0.152319\n",
      "f(x, y) = 0.114944\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# First we define the functions,\n",
    "def f(x, y):\n",
    "    return np.exp(-(2*x*x + y*y - x*y) / 2)\n",
    "\n",
    "def g(x, y):\n",
    "    return x*x + 3*(y+1)**2 - 1\n",
    "\n",
    "# Next their derivatives,\n",
    "def dfdx(x, y):\n",
    "    return 1/2 * (-4*x + y) * f(x, y)\n",
    "\n",
    "def dfdy(x, y):\n",
    "    return 1/2 * (x - 2*y) * f(x, y)\n",
    "\n",
    "def dgdx(x, y):\n",
    "    return 2 * x\n",
    "\n",
    "def dgdy(x, y):\n",
    "    return 6 * (y + 1)\n",
    "\n",
    "def DL(xyλ) :\n",
    "    [x, y, λ] = xyλ\n",
    "    return np.array([\n",
    "        dfdx(x, y) - λ * dgdx(x, y),\n",
    "        dfdy(x, y) - λ * dgdy(x, y),\n",
    "        - g(x, y)\n",
    "    ])\n",
    "\n",
    "(x0, y0, λ0) = (1, -1, 0)\n",
    "x, y, λ = sp.optimize.root(DL, [x0, y0, λ0]).x\n",
    "print(\"x = %g\" % x)\n",
    "print(\"y = %g\" % y)\n",
    "print(\"λ = %g\" % λ)\n",
    "print(\"f(x, y) = %g\" % f(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec6b9d72-0ac7-415e-9b2d-d53bacec5069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 0.957782\n",
      "y = 0.289565\n",
      "λ = -4.07789\n",
      "f(x, y) = -3.16222\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# First we define the functions, YOU SHOULD IMPLEMENT THESE\n",
    "def f(x, y):\n",
    "    return -np.exp(x - y**2 + x * y)\n",
    "\n",
    "def g(x, y):\n",
    "    return np.cosh(y) + x - 2\n",
    "\n",
    "# Next their derivatives, YOU SHOULD IMPLEMENT THESE\n",
    "def dfdx(x, y):\n",
    "    return (1 + y) * f(x, y)\n",
    "\n",
    "def dfdy(x, y):\n",
    "    return (x - 2 * y) * f(x, y)\n",
    "\n",
    "def dgdx(x, y):\n",
    "    return 1\n",
    "\n",
    "def dgdy(x, y):\n",
    "    return np.sinh(y)\n",
    "\n",
    "# Use the definition of DL from previously.\n",
    "def DL(xyλ) :\n",
    "    [x, y, λ] = xyλ\n",
    "    return np.array([\n",
    "        dfdx(x, y) - λ * dgdx(x, y),\n",
    "        dfdy(x, y) - λ * dgdy(x, y),\n",
    "        - g(x, y)\n",
    "    ])\n",
    "\n",
    "# To score on this question, the code above should set\n",
    "# the variables x, y, λ, to the values which solve the\n",
    "# Langrange multiplier problem.\n",
    "\n",
    "# I.e. use the optimize.root method, as you did previously.\n",
    "\n",
    "(x0, y0, λ0) = (0, 0, 0)\n",
    "x, y, λ = sp.optimize.root(DL, [x0, y0, λ0]).x\n",
    "\n",
    "print(\"x = %g\" % x)\n",
    "print(\"y = %g\" % y)\n",
    "print(\"λ = %g\" % λ)\n",
    "print(\"f(x, y) = %g\" % f(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4545ca3e-3ca1-41db-b16e-9e956a8835a6",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6064dfb-8627-4572-9c2a-b42d775237a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Here the function is defined\n",
    "def linfit(xdat,ydat):\n",
    "    # Here xbar and ybar are calculated\n",
    "    xbar = np.sum(xdat)/len(xdat)\n",
    "    ybar = np.sum(ydat)/len(ydat)\n",
    "    \n",
    "    # Insert calculation of m and c below\n",
    "    m = np.sum((xdat - xbar) * ydat) / np.sum((xdat - xbar)**2)\n",
    "    c = ybar - m * xbar\n",
    "    # Return your values as [m, c]\n",
    "    return [m, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450590fe-4950-4cd3-b7a6-43117b969668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "# Use the stats.linregress() method to evaluate regression\n",
    "regression = sp.stats.linregress(x=xdat, y=ydat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
